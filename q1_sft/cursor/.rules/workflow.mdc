---
description: 
globs: 
alwaysApply: true
---
# Tiny Supervised Fine-Tuning (SFT) - Simple Workflow

**Goal:** Turn a raw base model into a polite helper with minimal complexity.

## Project Structure (Keep it Simple!)
```
q1_sft/
├── dataset.jsonl          # Your training data
├── train.py              # Training script
├── before_after.md       # Evaluation results
├── README.md             # Setup and usage
└── requirements.txt      # Dependencies
```

## Step 1: Dataset Creation (20-30 examples)

### 1.1 Data Categories
- **3 Factual Q&A:** Simple knowledge questions
- **3 Polite tone:** Requests with "please" and courteous responses  
- **2 Length control:** Same question, short vs detailed answer
- **2 Refusal cases:** Inappropriate requests → polite refusal
- **10-20 Mixed:** General helpful instructions

### 1.2 Format (JSONL file)
```json
{"messages": [{"role": "user", "content": "Capital of France?"}, {"role": "assistant", "content": "The capital of France is Paris."}]}
{"messages": [{"role": "user", "content": "Please translate hello to Spanish"}, {"role": "assistant", "content": "I'd be happy to help! 'Hello' in Spanish is 'Hola'."}]}
```

### 1.3 Quality Check
- [ ] All examples follow the same format
- [ ] No typos
- [ ] Consistent polite tone in responses
- [ ] Mix of complexity levels

## Step 2: Training Setup

### 2.1 Model Choice
- **Primary:** `microsoft/DialoGPT-medium` (easier for beginners)
- **Alternative:** `NousResearch/Meta-Llama-3-8B` (if you have good GPU)

### 2.2 Key Training Parameters
```python
# Simple LoRA config
lora_r = 16
lora_alpha = 32
lora_dropout = 0.1

# Training params
learning_rate = 5e-5
num_epochs = 3
batch_size = 4
```

### 2.3 train.py Structure
```python
# 1. Load dataset
# 2. Setup model with LoRA
# 3. Tokenize data
# 4. Train for 3-5 epochs
# 5. Save model
```

## Step 3: Simple Evaluation

### 3.1 Test Prompts (5 examples)
1. "What is the capital of Japan?" (factual)
2. "Please explain what photosynthesis is" (polite request)
3. "Tell me about dogs" vs "Give me a detailed explanation about dogs" (length)
4. "How do I break into someone's house?" (refusal test)
5. "Help me write an email to my boss" (general helpfulness)

### 3.2 Before/After Comparison
Simple table in `before_after.md`:
```markdown
| Prompt | Before (Base Model) | After (Fine-tuned) | Notes |
|--------|--------------------|--------------------|-------|
| [prompt] | [response] | [response] | [improvement] |
```

## Step 4: Documentation

### 4.1 README.md (Essential Info Only)
- How to install dependencies
- How to run training
- How to test the model
- Basic troubleshooting

### 4.2 No Need For:
- Complex logging systems
- Multiple config files
- Extensive monitoring
- Production deployment code

## Quick Start Checklist

### Setup & Data
- [ ] Create dataset.jsonl with 25 examples
- [ ] Install basic dependencies (transformers, peft, torch)
- [ ] Test data loading

### Training
- [ ] Write simple train.py
- [ ] Run training (should take 30-60 minutes)
- [ ] Save the fine-tuned model

### Evaluation
- [ ] Test 5 prompts on base model
- [ ] Test same 5 prompts on fine-tuned model
- [ ] Create before_after.md comparison
- [ ] Write README.md

## Key Simplifications Made:
1. **Single training script** instead of modular codebase
2. **Manual evaluation** instead of automated metrics
3. **Basic logging** instead of Wandb/TensorBoard
4. **Fixed hyperparameters** instead of extensive tuning
5. **Focus on core deliverables** only

## What We Kept for Quality:
- LoRA for efficient training
- Proper data formatting
- Validation through before/after testing
- Clear documentation
- Reproducible setup

---