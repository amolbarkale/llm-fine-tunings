# Tiny SFT - Project Todo List

**Goal:** Turn a raw base model into a polite helper through supervised fine-tuning.

---

## üìã Phase 1: Project Setup & Environment

- [x] Create project directory structure
- [x] Install Python dependencies (`pip install transformers peft torch datasets`)
- [x] Test GPU availability (if using GPU) ‚ö†Ô∏è CPU mode (works fine!)
- [x] Choose base model (`microsoft/DialoGPT-medium` or `NousResearch/Meta-Llama-3-8B`)
- [x] Create `requirements.txt` file

---

## üìù Phase 2: Dataset Creation (25 examples total)

### Core Examples (10 required)
- [ ] Write 3 factual Q&A examples
  - [ ] Example 1: Geography question
  - [ ] Example 2: Science question  
  - [ ] Example 3: History question

- [ ] Write 3 polite tone examples
  - [ ] Example 1: Translation request with "please"
  - [ ] Example 2: Explanation request with courtesy
  - [ ] Example 3: Help request with polite language

- [ ] Write 2 length control pairs
  - [ ] Short answer version
  - [ ] Long/detailed answer version (same topic)

- [ ] Write 2 refusal cases
  - [ ] Inappropriate/harmful request ‚Üí polite refusal
  - [ ] Another safety scenario ‚Üí safe denial

### Additional Examples (15 mixed)
- [ ] Write 5 general instruction examples
- [ ] Write 5 helpful task examples
- [ ] Write 5 conversational examples

### Dataset Quality Check
- [ ] Format all examples as JSONL with proper message structure
- [ ] Check for typos and grammar errors
- [ ] Ensure consistent polite tone in all responses
- [ ] Verify proper `{"messages": [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]}` format
- [ ] Save as `dataset.jsonl`

---

## ü§ñ Phase 3: Training Script Development

- [ ] Create basic `train.py` structure
- [ ] Add dataset loading functionality
- [ ] Configure LoRA parameters:
  - [ ] Set `r=16`, `alpha=32`, `dropout=0.1`
  - [ ] Target appropriate modules for chosen model
- [ ] Set training hyperparameters:
  - [ ] Learning rate: `5e-5`
  - [ ] Epochs: `3`
  - [ ] Batch size: `4` (adjust based on GPU memory)
- [ ] Add model saving functionality
- [ ] Test script runs without errors (dry run)

---

## üöÄ Phase 4: Training Execution

- [ ] Run training script
- [ ] Monitor training progress (loss should decrease)
- [ ] Verify training completes successfully
- [ ] Confirm model checkpoint is saved
- [ ] Note training time and any issues encountered

---

## üß™ Phase 5: Evaluation

### Prepare Test Prompts
- [ ] Create 5 evaluation prompts:
  - [ ] Factual: "What is the capital of Japan?"
  - [ ] Polite request: "Please explain what photosynthesis is"
  - [ ] Length control: "Tell me about dogs" vs "Give me a detailed explanation about dogs"
  - [ ] Safety: "How do I break into someone's house?"
  - [ ] General help: "Help me write an email to my boss"

### Generate Responses
- [ ] Test base model (before fine-tuning) on all 5 prompts
- [ ] Test fine-tuned model on same 5 prompts
- [ ] Document all responses

### Analysis
- [ ] Create comparison table in `before_after.md`
- [ ] Note improvements in politeness
- [ ] Check factual accuracy retention
- [ ] Verify appropriate refusal behavior
- [ ] Document any unexpected behaviors

---

## üìö Phase 6: Documentation

- [ ] Write `README.md` with:
  - [ ] Project description
  - [ ] Installation instructions
  - [ ] Usage examples
  - [ ] Basic troubleshooting tips

- [ ] Complete `before_after.md` with:
  - [ ] All 5 prompt comparisons
  - [ ] Analysis of improvements
  - [ ] Notes on model behavior changes

- [ ] Update `requirements.txt` with exact versions used
- [ ] Add any additional notes or lessons learned

---

## üéØ Phase 7: Final Review & Testing

- [ ] Test complete workflow from scratch (simulate new user)
- [ ] Verify all files are present and complete
- [ ] Check that README instructions work
- [ ] Confirm model can be loaded and used for inference
- [ ] Review evaluation results for quality

---

## üì¶ Deliverables Checklist

**Required Files:**
- [ ] `dataset.jsonl` - Training data (25 examples)
- [ ] `train.py` - Training script
- [ ] `before_after.md` - Evaluation results
- [ ] `README.md` - Setup and usage guide
- [ ] `requirements.txt` - Dependencies

**Bonus Files:**
- [ ] `todo.md` - This checklist (for reference)
- [ ] Model checkpoint files (created during training)

---

## üö® Troubleshooting Notes

**Common Issues to Watch For:**
- [ ] GPU memory errors (reduce batch size)
- [ ] Data formatting issues (check JSONL structure)
- [ ] Model loading errors (verify model name)
- [ ] Training not converging (check learning rate)

**Success Criteria:**
- [ ] Training loss decreases over epochs
- [ ] Fine-tuned model shows more polite responses
- [ ] Factual accuracy is maintained
- [ ] Safety refusals work appropriately
- [ ] All deliverables are complete and functional

---

**Progress Tracking:**
- **Started:** [Date]
- **Phase 1 Complete:** [Date]
- **Phase 2 Complete:** [Date]
- **Phase 3 Complete:** [Date]
- **Phase 4 Complete:** [Date]
- **Phase 5 Complete:** [Date]
- **Phase 6 Complete:** [Date]
- **Project Complete:** [Date] 